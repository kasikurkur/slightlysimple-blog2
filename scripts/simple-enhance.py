#!/usr/bin/env python3
"""
ç°¡æ˜“è¨˜äº‹å“è³ªå‘ä¸Šã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼ˆPyYAMLãªã—ç‰ˆï¼‰
"""

import os
import sys
import re
import argparse
from pathlib import Path
from datetime import datetime

def read_markdown_file(file_path):
    """Markdownãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ã€ãƒ•ãƒ­ãƒ³ãƒˆãƒã‚¿ãƒ¼ã¨æœ¬æ–‡ã‚’åˆ†é›¢"""
    with open(file_path, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # YAML ãƒ•ãƒ­ãƒ³ãƒˆãƒã‚¿ãƒ¼åˆ†é›¢ï¼ˆç°¡æ˜“ç‰ˆï¼‰
    if content.startswith('---'):
        parts = content.split('---', 2)
        if len(parts) >= 3:
            frontmatter_text = parts[1].strip()
            body = parts[2].strip()
            return frontmatter_text, body
    
    return '', content

def parse_yaml_simple(yaml_text):
    """ç°¡æ˜“YAMLè§£æï¼ˆåŸºæœ¬çš„ãªkey: valueå½¢å¼ã®ã¿ï¼‰"""
    result = {}
    for line in yaml_text.split('\n'):
        line = line.strip()
        if ':' in line:
            key, value = line.split(':', 1)
            key = key.strip()
            value = value.strip().strip('"\'')
            
            # ãƒªã‚¹ãƒˆå½¢å¼ã®å‡¦ç†
            if value.startswith('[') and value.endswith(']'):
                # ç°¡æ˜“ãƒªã‚¹ãƒˆè§£æ
                items = value[1:-1].split(',')
                result[key] = [item.strip().strip('"\'') for item in items]
            else:
                result[key] = value
    
    return result

def generate_yaml_simple(data):
    """ç°¡æ˜“YAMLç”Ÿæˆ"""
    lines = []
    for key, value in data.items():
        if isinstance(value, list):
            formatted_list = '[' + ', '.join(f'"{item}"' for item in value) + ']'
            lines.append(f'{key}: {formatted_list}')
        else:
            lines.append(f'{key}: "{value}"')
    
    return '\n'.join(lines)

def extract_keywords_from_content(content):
    """ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‹ã‚‰ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æŠ½å‡º"""
    # æ—¥æœ¬èªã®å˜èªã‚’æŠ½å‡º
    words = re.findall(r'[ã-ã‚“ã‚¡-ãƒ¶ä¸€-é¾¯a-zA-Z0-9]+', content)
    
    # ã‚ˆãä½¿ã‚ã‚Œã‚‹å˜èªã‚’é™¤å¤–
    stop_words = {'ã“ã¨', 'ã‚‚ã®', 'ãŸã‚', 'ãªã©', 'ã«ã¤ã„ã¦', 'ã«ã‚ˆã‚‹', 'ã¾ã™', 'ã§ã™', 'ã§ã‚ã‚‹', 'ã™ã‚‹', 'ã‚Œã‚‹', 'ã‚‰ã‚Œã‚‹'}
    
    # é•·ã„å˜èªã‚’å„ªå…ˆ
    keywords = [word for word in words if len(word) >= 3 and word not in stop_words]
    
    return list(dict.fromkeys(keywords))[:10]

def generate_meta_description(title, content):
    """ãƒ¡ã‚¿ãƒ‡ã‚£ã‚¹ã‚¯ãƒªãƒ—ã‚·ãƒ§ãƒ³ç”Ÿæˆ"""
    first_paragraph = content.split('\n\n')[0]
    clean_text = re.sub(r'[#*`\[\]()]', '', first_paragraph)
    clean_text = re.sub(r'\n+', ' ', clean_text).strip()
    
    if len(clean_text) > 160:
        clean_text = clean_text[:157] + '...'
    
    return clean_text

def suggest_tags_from_content(content):
    """å†…å®¹ã‹ã‚‰é–¢é€£ã‚¿ã‚°ã‚’ææ¡ˆ"""
    tech_keywords = {
        'ChatGPT': ['ChatGPT', 'AI', 'äººå·¥çŸ¥èƒ½'],
        'AI': ['AI', 'äººå·¥çŸ¥èƒ½', 'æ©Ÿæ¢°å­¦ç¿’'],
        'ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°': ['ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°', 'é–‹ç™º', 'ã‚³ãƒ¼ãƒ‰'],
        'ãƒ–ãƒ­ã‚°': ['ãƒ–ãƒ­ã‚°', 'ãƒ–ãƒ­ã‚°é‹å–¶', 'ã‚³ãƒ³ãƒ†ãƒ³ãƒ„'],
        'SEO': ['SEO', 'æ¤œç´¢ã‚¨ãƒ³ã‚¸ãƒ³', 'ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°'],
    }
    
    suggested_tags = set()
    content_lower = content.lower()
    
    for keyword, tags in tech_keywords.items():
        if keyword.lower() in content_lower:
            suggested_tags.update(tags)
    
    return list(suggested_tags)[:5]

def main():
    parser = argparse.ArgumentParser(description='ç°¡æ˜“è¨˜äº‹å“è³ªå‘ä¸Šã‚¹ã‚¯ãƒªãƒ—ãƒˆ')
    parser.add_argument('file_path', help='å‡¦ç†ã™ã‚‹Markdownãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹')
    parser.add_argument('--dry-run', action='store_true', help='å®Ÿéš›ã®å¤‰æ›´ã¯è¡Œã‚ãšã€ææ¡ˆã®ã¿è¡¨ç¤º')
    
    args = parser.parse_args()
    
    if not os.path.exists(args.file_path):
        print(f"ã‚¨ãƒ©ãƒ¼: ãƒ•ã‚¡ã‚¤ãƒ« '{args.file_path}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        sys.exit(1)
    
    # Markdownãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿
    frontmatter_text, content = read_markdown_file(args.file_path)
    frontmatter = parse_yaml_simple(frontmatter_text)
    
    print(f"å‡¦ç†ä¸­: {args.file_path}")
    print("=" * 50)
    
    # æ”¹å–„ææ¡ˆ
    suggestions = {}
    
    if 'description' not in frontmatter or not frontmatter.get('description'):
        title = frontmatter.get('title', Path(args.file_path).stem.replace('-', ' ').title())
        suggestions['description'] = generate_meta_description(title, content)
    
    if 'tags' not in frontmatter or not frontmatter.get('tags'):
        suggestions['tags'] = suggest_tags_from_content(content)
    
    # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡º
    keywords = extract_keywords_from_content(content)
    
    print("ã€æ”¹å–„ææ¡ˆã€‘")
    for key, value in suggestions.items():
        print(f"  {key}: {value}")
    
    print(f"\nã€æŠ½å‡ºã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã€‘")
    print(f"  {', '.join(keywords[:5])}")
    
    if not args.dry_run and suggestions:
        # ãƒ•ãƒ­ãƒ³ãƒˆãƒã‚¿ãƒ¼æ›´æ–°
        updated_frontmatter = frontmatter.copy()
        updated_frontmatter.update(suggestions)
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
        with open(args.file_path, 'w', encoding='utf-8') as f:
            f.write('---\n')
            f.write(generate_yaml_simple(updated_frontmatter))
            f.write('\n---\n\n')
            f.write(content)
        
        print(f"\nâœ… ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ›´æ–°ã—ã¾ã—ãŸ: {args.file_path}")
    else:
        print(f"\nğŸ” Dry-runãƒ¢ãƒ¼ãƒ‰ã¾ãŸã¯æ›´æ–°ãªã—")

if __name__ == "__main__":
    main()