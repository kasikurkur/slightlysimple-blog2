#!/usr/bin/env python3
"""
è¨˜äº‹å“è³ªå‘ä¸Šã‚¹ã‚¯ãƒªãƒ—ãƒˆ
Claude APIã‚’ä½¿ç”¨ã—ã¦è¨˜äº‹ã®SEOæœ€é©åŒ–ã¨æ–‡ç« æ”¹å–„ã‚’è¡Œã†
"""

import os
import sys
import yaml
import re
import argparse
from pathlib import Path
from datetime import datetime

def read_markdown_file(file_path):
    """Markdownãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ã€ãƒ•ãƒ­ãƒ³ãƒˆãƒã‚¿ãƒ¼ã¨æœ¬æ–‡ã‚’åˆ†é›¢"""
    with open(file_path, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # ãƒ•ãƒ­ãƒ³ãƒˆãƒã‚¿ãƒ¼åˆ†é›¢
    if content.startswith('---'):
        parts = content.split('---', 2)
        if len(parts) >= 3:
            frontmatter = yaml.safe_load(parts[1])
            body = parts[2].strip()
            return frontmatter, body
    
    # ãƒ•ãƒ­ãƒ³ãƒˆãƒã‚¿ãƒ¼ãŒãªã„å ´åˆ
    return {}, content

def write_markdown_file(file_path, frontmatter, body):
    """ãƒ•ãƒ­ãƒ³ãƒˆãƒã‚¿ãƒ¼ã¨æœ¬æ–‡ã‚’Markdownãƒ•ã‚¡ã‚¤ãƒ«ã«æ›¸ãè¾¼ã¿"""
    with open(file_path, 'w', encoding='utf-8') as f:
        f.write('---\n')
        yaml.dump(frontmatter, f, default_flow_style=False, allow_unicode=True)
        f.write('---\n\n')
        f.write(body)

def extract_keywords_from_content(content):
    """ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‹ã‚‰ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æŠ½å‡ºï¼ˆç°¡æ˜“ç‰ˆï¼‰"""
    # æ—¥æœ¬èªã®å˜èªã‚’æŠ½å‡ºï¼ˆã²ã‚‰ãŒãªã€ã‚«ã‚¿ã‚«ãƒŠã€æ¼¢å­—ã€è‹±æ•°å­—ï¼‰
    words = re.findall(r'[ã-ã‚“ã‚¡-ãƒ¶ä¸€-é¾¯a-zA-Z0-9]+', content)
    
    # ã‚ˆãä½¿ã‚ã‚Œã‚‹å˜èªã‚’é™¤å¤–
    stop_words = {'ã“ã¨', 'ã‚‚ã®', 'ãŸã‚', 'ãªã©', 'ã«ã¤ã„ã¦', 'ã«ã‚ˆã‚‹', 'ã¾ã™', 'ã§ã™', 'ã§ã‚ã‚‹', 'ã™ã‚‹', 'ã‚Œã‚‹', 'ã‚‰ã‚Œã‚‹'}
    
    # é•·ã„å˜èªã‚’å„ªå…ˆã—ã¦ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã¨ã—ã¦æŠ½å‡º
    keywords = [word for word in words if len(word) >= 3 and word not in stop_words]
    
    # é‡è¤‡å‰Šé™¤ã—ã¦æœ€åˆã®10å€‹ã‚’è¿”ã™
    return list(dict.fromkeys(keywords))[:10]

def generate_meta_description(title, content):
    """ã‚¿ã‚¤ãƒˆãƒ«ã¨å†…å®¹ã‹ã‚‰è‡ªå‹•ã§ãƒ¡ã‚¿ãƒ‡ã‚£ã‚¹ã‚¯ãƒªãƒ—ã‚·ãƒ§ãƒ³ã‚’ç”Ÿæˆ"""
    # æœ€åˆã®æ®µè½ã‹ã‚‰160æ–‡å­—ç¨‹åº¦ã‚’æŠ½å‡º
    first_paragraph = content.split('\n\n')[0]
    # ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³è¨˜æ³•ã‚’é™¤å»
    clean_text = re.sub(r'[#*`\[\]()]', '', first_paragraph)
    # æ”¹è¡Œã‚’é™¤å»
    clean_text = re.sub(r'\n+', ' ', clean_text).strip()
    
    if len(clean_text) > 160:
        clean_text = clean_text[:157] + '...'
    
    return clean_text

def suggest_tags_from_content(content):
    """å†…å®¹ã‹ã‚‰é–¢é€£ã‚¿ã‚°ã‚’ææ¡ˆ"""
    # æŠ€è¡“ç³»ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®ãƒãƒƒãƒ”ãƒ³ã‚°
    tech_keywords = {
        'ChatGPT': ['ChatGPT', 'AI', 'äººå·¥çŸ¥èƒ½'],
        'AI': ['AI', 'äººå·¥çŸ¥èƒ½', 'æ©Ÿæ¢°å­¦ç¿’'],
        'ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°': ['ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°', 'é–‹ç™º', 'ã‚³ãƒ¼ãƒ‰'],
        'ãƒ–ãƒ­ã‚°': ['ãƒ–ãƒ­ã‚°', 'ãƒ–ãƒ­ã‚°é‹å–¶', 'ã‚³ãƒ³ãƒ†ãƒ³ãƒ„'],
        'SEO': ['SEO', 'æ¤œç´¢ã‚¨ãƒ³ã‚¸ãƒ³', 'ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°'],
        'Python': ['Python', 'ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°', 'é–‹ç™º'],
        'JavaScript': ['JavaScript', 'Webé–‹ç™º', 'ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°'],
    }
    
    suggested_tags = set()
    content_lower = content.lower()
    
    for keyword, tags in tech_keywords.items():
        if keyword.lower() in content_lower:
            suggested_tags.update(tags)
    
    return list(suggested_tags)[:5]  # æœ€å¤§5å€‹ã¾ã§

def enhance_frontmatter(frontmatter, content, file_path):
    """ãƒ•ãƒ­ãƒ³ãƒˆãƒã‚¿ãƒ¼ã‚’å¼·åŒ–"""
    enhanced = frontmatter.copy()
    
    # ã‚¿ã‚¤ãƒˆãƒ«ãŒãªã„å ´åˆã¯ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰ç”Ÿæˆ
    if 'title' not in enhanced:
        enhanced['title'] = Path(file_path).stem.replace('-', ' ').title()
    
    # æ—¥ä»˜ãŒãªã„å ´åˆã¯ç¾åœ¨ã®æ—¥ä»˜ã‚’è¨­å®š
    if 'date' not in enhanced:
        enhanced['date'] = datetime.now().isoformat()
    
    # draftè¨­å®šãŒãªã„å ´åˆã¯falseã«è¨­å®š
    if 'draft' not in enhanced:
        enhanced['draft'] = False
    
    # ãƒ¡ã‚¿ãƒ‡ã‚£ã‚¹ã‚¯ãƒªãƒ—ã‚·ãƒ§ãƒ³ãŒãªã„å ´åˆã¯è‡ªå‹•ç”Ÿæˆ
    if 'description' not in enhanced:
        enhanced['description'] = generate_meta_description(enhanced.get('title', ''), content)
    
    # ã‚¿ã‚°ãŒãªã„å ´åˆã¯è‡ªå‹•ææ¡ˆ
    if 'tags' not in enhanced:
        enhanced['tags'] = suggest_tags_from_content(content)
    
    # ã‚«ãƒ†ã‚´ãƒªãŒãªã„å ´åˆã¯ã‚¿ã‚°ã‹ã‚‰æ¨å®š
    if 'categories' not in enhanced and enhanced.get('tags'):
        enhanced['categories'] = [enhanced['tags'][0]]  # æœ€åˆã®ã‚¿ã‚°ã‚’ã‚«ãƒ†ã‚´ãƒªã«
    
    return enhanced

def main():
    parser = argparse.ArgumentParser(description='è¨˜äº‹å“è³ªå‘ä¸Šã‚¹ã‚¯ãƒªãƒ—ãƒˆ')
    parser.add_argument('file_path', help='å‡¦ç†ã™ã‚‹Markdownãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹')
    parser.add_argument('--output', help='å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ï¼ˆæŒ‡å®šã—ãªã„å ´åˆã¯å…ƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¸Šæ›¸ãï¼‰')
    parser.add_argument('--dry-run', action='store_true', help='å®Ÿéš›ã®å¤‰æ›´ã¯è¡Œã‚ãšã€ææ¡ˆã®ã¿è¡¨ç¤º')
    
    args = parser.parse_args()
    
    if not os.path.exists(args.file_path):
        print(f"ã‚¨ãƒ©ãƒ¼: ãƒ•ã‚¡ã‚¤ãƒ« '{args.file_path}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        sys.exit(1)
    
    # Markdownãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿
    frontmatter, content = read_markdown_file(args.file_path)
    
    print(f"å‡¦ç†ä¸­: {args.file_path}")
    print("=" * 50)
    
    # ãƒ•ãƒ­ãƒ³ãƒˆãƒã‚¿ãƒ¼å¼·åŒ–
    enhanced_frontmatter = enhance_frontmatter(frontmatter, content, args.file_path)
    
    # å¤‰æ›´ç‚¹ã®è¡¨ç¤º
    print("ã€ãƒ•ãƒ­ãƒ³ãƒˆãƒã‚¿ãƒ¼å¤‰æ›´ç‚¹ã€‘")
    for key, value in enhanced_frontmatter.items():
        if key not in frontmatter:
            print(f"  è¿½åŠ : {key} = {value}")
        elif frontmatter[key] != value:
            print(f"  å¤‰æ›´: {key} = {frontmatter[key]} â†’ {value}")
    
    # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡ºçµæœè¡¨ç¤º
    keywords = extract_keywords_from_content(content)
    print(f"\nã€æŠ½å‡ºã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã€‘")
    print(f"  {', '.join(keywords[:5])}")
    
    # dry-runã§ãªã„å ´åˆã¯å®Ÿéš›ã«ä¿å­˜
    if not args.dry_run:
        output_path = args.output or args.file_path
        write_markdown_file(output_path, enhanced_frontmatter, content)
        print(f"\nâœ… ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ›´æ–°ã—ã¾ã—ãŸ: {output_path}")
    else:
        print(f"\nğŸ” Dry-runãƒ¢ãƒ¼ãƒ‰: å®Ÿéš›ã®å¤‰æ›´ã¯è¡Œã‚ã‚Œã¦ã„ã¾ã›ã‚“")

if __name__ == "__main__":
    main()